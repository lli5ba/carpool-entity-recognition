{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import naive_bayes\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('posts/shuffled_posts.csv', encoding = 'latin1')\n",
    "relevant_ix = []\n",
    "for index, row in data.iterrows():\n",
    "    if row['is_relevant'] == 1:\n",
    "        relevant_ix.append(index)\n",
    "data_annotated = data.ix[relevant_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "text = []\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "for index, row in data_annotated.iterrows():\n",
    "    full_text = row['status_message'].lower()\n",
    "    tk_text = nltk.word_tokenize(full_text)\n",
    "    stemmed = [stemmer.stem(token) for token in tk_text]\n",
    "    text.append(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct vocabulary with ttf\n",
    "k = 10\n",
    "ttf = {}\n",
    "for words in text:\n",
    "    for word in words:\n",
    "        if word not in ttf:\n",
    "            ttf[word] = 1\n",
    "        else:\n",
    "            ttf[word] += 1\n",
    "vocab = [word for word in ttf.keys() if ttf[word] >= k and not re.search('\\d', word)] # high word count and not date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create feature vectors\n",
    "X = []\n",
    "for row in text:\n",
    "    X_row = []\n",
    "    for voc in vocab:\n",
    "        if voc in row:\n",
    "            X_row.append(1)\n",
    "        else:\n",
    "            X_row.append(0)\n",
    "    X.append(X_row)\n",
    "X = np.matrix(X)\n",
    "#X_relevant = X.ix[X['is_relevant'] == 1]\n",
    "y_driver = np.array(data_annotated['is_driver'])\n",
    "y_roundtrip = np.array(data_annotated['is_roundtrip'])\n",
    "#y_relevant = data_annotated['is_relevant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# machine learning!\n",
    "clf = skl.naive_bayes.GaussianNB()\n",
    "clf.fit(X, y_driver)\n",
    "pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to do: model selection, evaluation, etc.\n",
    "count = 0\n",
    "for i in range(len(y_driver)):\n",
    "    if y_driver[i] == pred[i]:\n",
    "        count += 1\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
